![](images/statements.png#fullpagewidth)

## Intro

Professed values of the early internet, such as “decentralisation”, “openness”, “freedom”, and “security” are falling short in light of contemporary geopolitical, economic, and environmental challenges.  Current reconfigurations of information networks are aimed at the extraction of control and revenue from data streams, without considering planetary boundaries or social justice.  Like others, we have come to the conclusion that the internet imaginary has run out of steam. 

The critical infrastructure lab interrogates media and control infrastructures that are critical to societies.  It does so through a critical analysis of power, regimes, and conflicts in infrastructure governance.  To develop new infrastructural imaginaries that centre people and planet over profit and capital, the critical infrastructure lab, the Green Web Foundation, and Share Foundation organised an in-person workshop at a monastery in Perast, ^[The Franciscan monastery is dedicated to St. Anthony of Padua.] Montenegro in July 2023.  The retreat looked at shifting power in media infrastructures through three lenses: standards, environment, and geopolitics.  In this essay, we reflect on the conversation and insights we gained at the workshop.

The term “we” here is meant to reflect the conversations that happened in Perast.  However, only the lab members are responsible for the mistakes found herein.  Even though we do not attribute remarks, findings, or opinions to individual participants, we do very much recognise the labour, experience, and expertise that were needed to produce them.  We share these insights produced collaboratively in the spirit of “learning in the open”, which is a guiding principle of work in the lab.

## From ChatGPT to Just Infrastructures 

To imagine a different future we first need to unpack and understand the ideologies that are driving our contemporary networks.  Artificial intelligence is all the rage today.  Large Language Models (LLMs) — such as ChatGPT — reproduce the *status quo* as the always emergent, yet still inevitable future, while gushing up energy.  In contrast, we believe in infrastructure politics as a means for environmental and social justice.  When we ask ChatGPT to look at communication networks through the lens of geopolitics, standards, and environment, we see how the neoliberal market ideology and the politics that support it are obfuscated and embedded in seemingly neutral reflections of our infrastructural realities. 

The Italian political philosopher Antonio Gramsci would call attention to exactly this phenomenon, that the ruling ideology of the time becomes the *common sense*, widely disseminated in society through culture and institutions.  Thus, the common sense of the day serves the partial interests of capital.  ChatGPT, fed on whatever is found by its predatory harvesters on the World Wide Web, does such a job of reflecting the common sense.  We used its output as a starting point of critical discussions.

######  *“What is a network ideology for communication networks that takes standards and standard-setting into account?”*

In a description of the network ideologies of the European Union, China, Russia and the United States, the ChatGPTv3 model presents a narrative in which Europe and the United States are positioned as the vanguards of the open, free, and secure internet.  In the same description, China and Russia are the actors who want to control the network in order to oppress their societies.  When we asked “what is a network ideology for communication networks that takes standards and standard-setting into account?”, ChatGPTv3 primarily saw standards as a way to facilitate and accelerate the market.  In response to the prompt “what is a network ideology for communication networks that takes the environment into account?”, ChatGPTv3 offers an overview of the material impact of infrastructures that should be managed to facilitate economic expansion.  The answer suggests that the environment is primarily a constraint on progress.  Following the logic of the model, we observe that the dominant common sense today is to frame the environment as an obstacle for the infinite growth, an obstacle that can be surmounted through increased efficiency and optimisation. 

Power and representation lingers beneath the surface of these generated texts, but it is never articulated.  As such, the model — and often the public discourse itself — overlooks important questions around which ideologies, interests, people, and territories are privileged in the dominant understanding of networks, and which are cast into the background of the discourse.  In Perast, we explored ways in which we can overcome these dominant narratives.

### ![](images/5G.png#fullpagewidth)

## Standards: Re-Imagining 5G 

<!-- 1120 words -->

###### Actors who championed the public interest in the case of the Internet apply a double standard to telecommuni-cations, as if there would be nothing to improve on telephone networks.

The next generation of communication protocols and standards, called 5G, has the potential to radically change networks, yet at the moment these changes are not adequately optimised for people and planet.  We are witnessing a consolidation of every layer of the stack that is influencing how and who is serving the user.  Take, for example, how the use of underlying IP and TCP protocols in modern telecommunication networks has eradicated the difference between Internet Service Providers (ISPs) and telecommunication providers (telcos).  In addition, the overwhelming majority of the last mile market is in the hand of a relatively small number of telcos, who can then easily become gatekeepers of access. 

It is very hard to demand that these telcos change, both because of their size and their historical position.  However, with the implementation of 5G, there is a historical opportunity for civil society to intervene in the reconfiguration of telecommunication networks — or to choose not to.  The potential reconfiguration that comes with the roll out of 5G is discussed by engineers under terms such as Software Defined Networking (SDN), Network Function Virtualisation (NFV), and edge computing.  Two potential pathways for influencing telecommunications architectures that involve these advanced features have been identified and discussed at the retreat.  One pathway would be the engagement with community ISPs, and the other would be re-framing spectrum allocation auction policies.

**Community networks** come in many shapes and sizes, ^[See RFC7962 for a comparison: <https://datatracker.ietf.org/doc/html/rfc7962>.] but overall, they are generally more open ideologically, and pay more attention to the values of the consumers or communities that they serve, when considered in comparison to larger Telcos.  As such, community networks could offer space to experiment with how 5G could be used for energy reduction, countering planned obsolescence, providing stronger privacy guarantees, and making resources such as computation at the edge of the network available to end users. 

The possible barriers to the engagement with community networks are cultural, economic and technical.  Community service providers rarely see 5G as legitimate access network technology, no matter if those providers are in the business of providing Internet connectivity through community wireless networks, cooperatively managed fibre cables, or mobile phone services.  5G deployments are associated with the corporations that dominate the consolidated market, and assumed to be optimised for enterprise use cases.  As an emerging technology, the hardware itself is notoriously expensive, especially in times of global shortages in the supply chain of high-tech chip-making and antenna-manufacture.  The protocol stack that drives the hardware is orders of magnitude more complex than the already complicated 4G networks.  The enterprise profile, hefty price tag, and deep complexity of 5G presents a high barrier for adoption by community networks.  Fortunately, none of these barriers are necessarily insurmountable.  Similar arguments have been brought against 3D printers, laser cutters, surveillance drones, or biotechnology, just to mention a few dominant technologies that have indeed been repurposed and reinvented since the beginning of the millennium.

Opportunities include an increased understanding of energy use in different parts of the network, thanks to better the introspection and diagnostics built into the advanced communication protocols and hardware standards.  Through community experimentation, we could discover whether 5G can be built sustainably at all, and if yes, how these insights can be used to contribute to upstream code-bases, standard-setting and regulation.  Other opportunities are enabling end-users to reconfigure the network and make use of (temporary) computation and storage in the network, to alter the power relation between telcos, service providers, and network users.  The programmability of the infrastructure could potentially enable better default settings and stronger guarantees for safeguarding private information and disclosing information that should be part of the public record.

**Spectrum auctions** are the main instrument for spectrum allocation, because the electro-magnetic spectrum in which radio waves travel is seen as a scarce natural resource.  Even through technological innovations now enable more economic uses of the electro-magnetic spectrum, this assumptions of scarcity still guides the *spectrum allocation policies*.  These policies are different in different countries.  For instance, some countries allocate frequencies for an indefinite time frame, while others do so for a limited number of years.  In some countries, the spectrum authorities have the right to revoke the granted licences.  Whatever the allocation time frame and the exact conditions be, however, the spectrum is allocated through auctions, where the right to use the advertised frequency range goes to the highest bidder.

The auction model has been around for a while, yet little has been learned from the historic spectrum actions.  Some have argued that the protectionist state, which seeks to promote selected domestic telco companies as national champions, is in fact destroying them through auctioning additional frequencies for 5G protocols.  This model inflates the market.  The state essentially sells off monopoly access to a newly created market segment.  Even if that market segment is not necessarily growing, national champions feel that they have to capture it from the competition.  As a result, world-leading telecommunication corporations choose to go into dept, and sell other assets to cover their losses.

When we approach spectrum allocation not as an economic transaction, but a governance regime, then different opportunities emerge.  Auctions are currently organised according to the logic of capital, and nation states are invested in this model because they receive significant income from them.  If we centre the public interest in spectrum allocation, auctions will most likely not be the best way forward, because other criteria, other than the highest bidder, become important.  Opening up the method of governance allows for the introduction of a multi stakeholder model, which is the current norm in Internet governance. ^[“Use-it-or-share-it” approaches to spectrum allocation in the USA, UK, Canada and South Africa seek to diversify the actors that can have access to frequencies after auctioning them, recognising the limitations of granting exclusive access to the highest bidder. See  <https://cis-india.org/telecom/comments-and-recommendations-to-trai>.]

In conclusion, actors who championed the public interest in the case of the Internet apply a double standard to telecommunications, as if there would be nothing to improve on telephone networks.  Neither civil society, nor policy makers consider even the most basic values associated with the Internet — such as free, open, secure — applicable to mobile phone networks.   This leads to a strange situation where emerging technologies reconfigure power relationships on the global stage and in the context of our everyday lives, all the while “Internet activists” are fixing the networks we relied on decades ago.

### ![](images/limits.png#fullpagewidth)

## Environment: Limits, Reduction, and Redistribution

<!-- 1218 words -->

###### Local municipalities, provinces, and national governments have significant power to decide if, where, and under which conditions data centres can be build.

People have been protesting against the arrival of new data centres in Chile, the Netherlands, Ireland, Spain, and United States.  These protest are fuelled by fundamental concerns about the distribution of land, water, and energy resources, as well as more populist “not in my back yard” politics.  In places where “the people won”, and building plans were halted, the victory merely displaced the problem to other territories.  This begs the question: can there be any other outcome when we merely challenge a specific location, or a specific function of internet and communication networks, rather than the the ideology of abundance, growth, and infinite resources that underpins our communication infrastructures today?  If not, then how do we rethink data centres, as a physical representation of a larger infrastructure, all together?  A pathway for reshaping European data centre policy can start from _limits, reduction, and redistribution_ and the _prioritisation of data and computational processes for the public good_. 

A common sense approach these days to minimising the environmental impact of communication networks is the focus on increased _efficiency and effectiveness_, especially energy consumption.  Here, there are still many unknowns.  Can data centres be planned to switch on and off depending on the availability of energy?  What is less polluting in terms of resource consumption: smaller or bigger data centres?  What is the least polluting coolant: drinking water, ground water, or air?  More questions could be asked.  A common critique of the narrow focus on carbon reduction and water usage is that it fails to take the environmental impacts of the hardware and software life cycle into account and assumes the demands of the network do not increase exponentially.  Yet, even within the narrow confines of electricity consumption, the attention is on the measurement of particular devices and installations, rather than on the aggregate power usage of communication infrastructures.  ^[The cryptocurrency Bitcoin is an exception to this rule, because it is relatively easy to measure the total electricity costs of its infrastructure, resulting in frequent comparisons between the resource consumption of particular countries and the Bitcoin network.] 

**Limitation and redistribution** of resources should be the basis of data centre policy, yet the ideology of optimisation serves to hide any serious discussion on the topic.  The debate on efficiency and effectiveness obfuscates other trends in the data centre industry that points towards infinite growth.  For instance, hyperscalers build data centres in order to be able to host an ever expanding Metaverse, or have our streaming content ready at a click of a mouse.  In light of the ecological crisis, we should ask whether it is acceptable to facilitate these extractive infrastructures, or whether we owe it to the planet — as well as the current and future generations — to create a new green calculus that is based on the prioritisation of the the public interest through resources minimisation.  To this end, we need to start identifying data centre types and their use cases, building a taxonomy ranging from data centres that are critical infrastructure to others that are used solely to turn a profit. 

In parallel to studying data centres with a view to their limitation and the redistribution of their impacts, the very principles of limitation and redistribution need to be clarified and articulated.  Most importantly, the mutual dependency between limitation and redistribution needs to be safeguarded.  For instance, the limitation of harms from data centres should not be confined to societies that can better defend themselves, and the redistribution of the benefits from data centres should benefit everyone.  A viable, but unjust society is as undesirable as an environmentally unsustainable society where social justice prevails.  There will always be attempts to privilege one principle over the other, as capital seeks to integrate the critique of environmental movements into the mirage of a green economy.  Therefore, the promoters of limitation and redistribution should anticipate and prepare for divide and conquer strategies that aim to neutralise social change.

The ideas of limitation and redistribution can be anchored in the framework of the “doughnut economy”.  ^[Raworth, Kate. 2017. *Doughnut Economics: Seven Ways to Think Like a 12-Century Economist*. White River Junction, VT: Chelsea Green.]  Doughnut economy seeks a safe and just society, to be located within the phase space of the global economy.  Such a safe and just space for a possible future society is delineated by two boundary conditions, defined as the planetary _and_ social boundaries within humanity can thrive.  The limitation of the natural resource consumption of industrial civilisation is necessary to stay within planetary boundaries, but so is the redistribution of public goods.  Arguably, one would not work without the other.

Reduction is a useful complementary concept of great strategic significance, because limitless economic _growth_ is often posited as the ultimate pathway to both the optimisation of resources and the redistribution of wealth.  Market mechanisms for such growth are supposed to yield long term social benefits for everybody thanks to the optimal allocation of resources.  ^[The “calculation debate” in the history of economy was a debate about which kind of economy can lead to the optimal allocation of resources, even though few participants questioned the definition of optimality at the time.]  Only that is how it is possible to envision a green transition based on even more intensive industrial activity and an acceleration of economic exchange that is enabled by the proliferation of data centres in the landscape.

**Ownership, governance, and participation** are key to advance towards rethinking and remaking data centre policy.  The companies building the largest data centres in Europe are the same ones that we recognise from the World Wide Web as social media monopolies, such as Google, Amazon, Facebook, Apple or Microsoft (the so-called GAFAM).  These corporations appear invincible because of their grasp on the digital market.  However, they can be — and often are already — challenged successfully in the data centre space.

Local municipalities, provinces, and national governments have significant power to decide if, where, and under which conditions data centres can be build.  That is because they exercise sovereignty (ultimate authority) over the land, including the the land where data centres would be built and the electro-magnetic spectrum in which computation physically takes place.  To ensure just — and just enough — communication networks, we need to stay within planetary boundaries and weigh increased data storage and computation against the ecological impact of network infrastructure.  Criteria for the provision of permits needed to construct and run data centres should be used to evaluate proposals based on aspects such as digital sobriety, data and computational obsolescence, public archiving, open source hardware and software, transparency about the volume of data transactions, and the openness for public inspection.

Such changes can happen if more and different actors get involved in shaping data centre policy and practice, something that we already see happening to a certain extent.  However, actors who wish to advance the public interest need to coordinate and strategise to avoid displacing the problem to weaker jurisdictions.  Limits, reduction and redistribution have to become global values that users, publics and regulators expect from technologies and which are incorporated into both the relevant technical standards and the applicable governance mechanisms.

### ![](images/sail.png#fullpagewidth)


## Geopolitics: What Can Government Do?

<!-- 938 words  -->

###### Digital infrastructures built on open standards, implemented with free software and open hardware solutions, and deployed in publicly advertised and cryptographically verifiable configurations can serve as strong foundations of sovereign nations.

A cursory analysis showed that governments have different approaches to markets.  For instance, the United States seeks to maintain an unregulated market, whereas Europe seeks to have a regulated market, and China organises a planned market.  These different economic policies can lead to tensions especially when they mix with the foreign policy of the respective countries.  Relationships between vendors on global markets from digital platforms through telecommunications to chip making are increasingly shaped by direct political interference.

**Geopolitical conflicts put tensions on global supply chains**.  The protectionist trade policies that were believed to have disappeared after nearly three decades of neoliberal globalisation are now revived as a response to geopolitical tensions.  Examples include sanctions against the Chinese telecommunications vendor Huawei, as well as more recent export restrictions that hit the Dutch chip making vendor ASML.  ^[ASML supplies photo-lithography systems for the semiconductor industry, being the single vendor for many advanced techniques used by the leading chip making firms in Taiwan, Japan, the USA, etc.]  The latter case shows that digital sovereignty is only attainable for global superpowers, who can force trade policies on other countries, while bringing them further under their sphere of influence.

Nonetheless, ambitious countries on the world stage such as the BRICS (Brazil, Russia, India, China and South Africa) increasingly see the participation in standards processes as a possible and necessary pathway to geopolitical influence and national sovereignty.  A similar direction have been enshrined into the new European Council standards strategy as well, emphasising global leadership internationally and a resilient green transition within the single market.  While the approaches of different countries and government bodies remain very different indeed, standards are increasingly associated with both political influence and human values.

Current standardisation approaches in the West are often based on the assumption that communication networks should be _open, free, and secure_.  The lab is working with governments and governance bodies to explore how these values hold under the current technical, economic, and geopolitical tensions.  We found that these concepts have never been very clearly defined, which allowed for strategic ambiguity in their use.  The ambiguity allowed different parts of the government to claim to be promoting these values even when their policy goals did not match up.  As telecommunications networks and internet networks merge, there is an increased need to harmonise divergent information policies and revise potentially ill-defined policy objectives.

**How smaller countries navigate these geopolitical dynamics** towards advancing the public interest in digital communication networks was one of the primary topics of the discussion.  An open and accountable technological stack legitimises the government by redistributing power to other actors.  Networks can become a public good that everyone benefits from.

Digital infrastructures built on open standards, implemented with _free software and open hardware_, and deployed in publicly advertised and _cryptographically verifiable configurations_ can serve as strong foundations of sovereign nations.  Digital sovereignty, as a strategic goal for a nation to be in control of its electronic assets and information flows, has barely been attained by any state on Earth.  Openness is not sufficient to attain digital sovereignty, because the infrastructure is not necessarily maintained or owned by the nation state itself.  Nonetheless, openness is one of the necessary preconditions for empowering smaller actors in view of digital sovereignty.

What this means for governmental engagement in standard-setting is that open standards, and the open software and hardware implementation of standards, should be an inherent part of government _procurement rules, tenders, and spectrum auctions_.  Furthermore, governments should stimulate participation in standard-setting by standard takers, such as consumer organisations, small and medium enterprises, civil society, and academia.  So-called “non-aligned states” can serve as allies for advancing openness on the basis of such strategic considerations.

Even where a multi-stakeholder approach would not be feasible to argue for, governments should use their considerable influence to promote _open and transparent standards processes_ as a minimum.  Meetings of standards bodies should be open to participation by the public, and archived as a matter of public record.  Furthermore, the outputs of standardisation, such as the standards documents themselves, should be public.  The rules of engagement should favour the participation of a wider range of people beyond the usual suspects.  Open standards processes are all the more important as legislators in the European Union (and increasingly elsewhere) refer ethical and political questions to national and regional standards bodies, effectively enlarging their mandates.  Governments of small nation states can lead by example when they introduce open standards processes to the working routines of their national standards bodies, and then promote open processes within international standards development organisations as best practices.

_Open standards processes_ would also support more research and reflection that could inform strategy.  We identified a lack of actionable research in this area.  The social impact of industrial standards can be easily demonstrated by a few examples, but strategic planning should be based on a more systematic understanding that allows for the normative evaluation of particular proposals.  Right now, it is difficult to triangulate between political objectives, societal needs, and the technical measures prescribed by standards.  There is also a lack of tools to measure the effectiveness of standards, the environmental impact of standardised technologies, or the contribution of standardisation processes to the public good.  Finally, long _term policy objectives_ would help to coordinate between governmental bodies, civil society actors, industry players and other participants in multi-stakeholder or multilateral standardisation.


## Lab as an infrastructure

The unresolved questions of who are the “people” and what is the “public interest” loomed large over our gathering, and we faced these hard questions head on in the morning of the last day.  We realised that it is one thing that we can articulate the positionality of the lab as an academic-interventionist organisation based in the city centre of Amsterdam, the Netherlands — but it is another thing to take on the responsibility of speaking in the name of the planet and the people.  In order to create space for developing infrastructural futures collaboratively, we would need to carefully seek out, live through, and take into account the experiences produced by contemporary infrastructural geopolitics, standards and environments in a wide range of local contexts all over the planet.  A demand as ambitious as it is necessary.  What we can certainly do, however, is to look for witnesses, allies and collaborators who bring these perspectives into our works, routines and outputs, while acknowledging the limitations of our own approaches.

People who are interested in exploring and working towards communication networks that support life, that centre people and planet, and want to question and unlearn who we look and listen to for solutions: reach out to us, and/or join our reading groups!


## Who was in the room

We want to thank all the participants of the Perast event — Alexandra Haché, Andreas Baur, Jedrzej Niklas, Ivy Yang, Mallory Knodel, Marieke van Dijk, Michelle Thorne, Mushon Zer Aviv, Naomi Appelman, Olivia Solis, Rahul Mukherjee, Sofija Stefanović, Yan Cong, and Zuzanna Warso.  A special appreciation goes out to the Share Foundation, specifically Đorđe Krivokapić, Nevena Krivokapić, Filip Milošević, and Bojan Perkov.

\ 

\ 

\ 

\ 

\ 

\ 

![](images/boat.png#fullpagewidth){width=130% height=130%}


## About the lab

The critical infrastructure lab researches power and contestation in transnational media infrastructures.  The lab aims to create space to co-develop alternative infrastructural futures that recenter people and planet over profit and capital.  We aim to do this by establishing a community around three infrastructural subtopic (geopolitics, standards, environment), producing a sound body of research, as well as developing strategic insights and actionable policy recommendations.

> <https://www.criticalinfralab.net/>

